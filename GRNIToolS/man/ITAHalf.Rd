% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ITAHalf.R
\name{ITAHalf}
\alias{ITAHalf}
\title{ITAHalf - iterative half thresholding algorithm}
\usage{
ITAHalf(A, b, x0, sparsity, MaxIter = 200, epsilon = 1e-06)
}
\arguments{
\item{A}{Gene expression data of transcriptome factors (i.e. basis function in machine learning).}

\item{b}{Gene expression data of target genes (i.e. observation in machine learning).}

\item{x0}{Gene expression data of Chromatin immunoprecipitation or zero vector (i.e. initial iterative point in machine learning).}

\item{sparsity}{Sparsity level of solution.}

\item{MaxIter}{Maximum iteration used in calculation; we set default as 200.}

\item{epsilon}{Stopping rule in algorithm where the rule is \eqn{||Ax-b|{|_2^2} < \epsilon}; we set default as 1e-6.}
}
\description{
This function is the process of ITA-Half algorithm aims to solve \eqn{l_{\frac{1}{2}}} regularization optimization model, and it is an extension of ISTA.
}
\details{
Iterative half thresholding algorithm (ITA-Half) was introduced by Xu et al. (2012), which is an extension of the ISTA for solving the \eqn{l_{\frac{1}{2}}} regularization problem:
\deqn{{\min}_{x \in R^n} ||Ax - b|{|_2^2} + \lambda ||x|{|_{1/2}^{1/2}}}
Similar to ISTA, the idea of ITA-Half is to sequentially proceed a gradient descent step and a half thresholding operator at each iteration.
}
\references{
Xu, Z., Chang, X., Xu, F., and Zhang, H. (2012). "\eqn{l_{\frac{1}{2}}} regularization: A thresholding representation theory and a fast solver", IEEE Transactions on Neural Networks and Learning Systems, 23, 1013-1027.

Hu, Y., Li, C., Meng, K., Qin, J., and Yang, X. (2017). "Group sparse optimization via \eqn{l_{p,q}} regularization", Journal of Machine Learning Research, 18(30), 1-52.
}
\author{
Yaohua Hu <mayhhu@szu.edu.cn> 

Xinlin Hu <ttxinlinhu@qq.com>
}
