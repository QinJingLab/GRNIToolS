% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/demo_reg.R
\name{demo_reg}
\alias{demo_reg}
\title{Demo reg - The demo of regression method}
\usage{
demo_reg(
  A,
  B,
  seq,
  X,
  algorithm = "ADMM",
  max.steps = 200,
  TF,
  gene,
  p = FALSE,
  tau = 10,
  cl.cores = 2,
  file = NULL,
  verbose = TRUE
)
}
\arguments{
\item{A}{Gene expression data of transcriptome factors. Expression matrix (tfs x samples). Every row is a tf, every column is a sample. 
The class of A are required to be 'matrix' and the dimension of matrix A is m * n.}

\item{B}{Gene expression data of target genes. Expression matrix (genes x samples). Every row is a gene, every column is a sample. 
The class of B are required to be 'matrix' and the dimension of matrix B is u * n.}

\item{seq}{Sparsity level of solution. User can input a sequence of sparsity, i.e. 's <- c(1,2,3,4,5)'.}

\item{X}{Gene expression data of Chromatin immunoprecipitation or zero matrix.The class of X are required to be
'matrix' and the dimension of matrix X is u * m.}

\item{algorithm}{We provide 12 algorithms in this function including 'ADMM', 'ADMMHalf',
'ADMMHard', 'ITAHalf', 'ITAHard', 'ISTA', 'SPGL0', 'SPGL1', 'CoSaMP', 'OMP', 'FoBa' and 'LARS'. Default: ADMM.}

\item{max.steps}{Maximum iteration used in calculation. Default: 200.}

\item{TF}{The Transcription Factors (TFs) The default value NULL means that all the genes are used as candidate regulators. Default: NULL.}

\item{gene}{A vector of characters containing the target genes.}

\item{p}{If set to FALSE, this demo aims to use the algorithms in lasso type conveniently.If set to TRUE, this demo aims to use the algorithms in plasso type conveniently(The matrix X must need).Default: FALSE.}

\item{tau}{Tuning parameter of prior lasso (plasso); using cross-validation can get a great one to calculate. The default is 10.}

\item{cl.cores}{The number of cores in computer that you want to utilize. Default: 2.}

\item{file}{A connection, or a character string naming the file to write to. The default not save the grn matrix. Default: NULL.}

\item{verbose}{If set to TRUE, a feedback on the progress of the progress of the calculations is given. Default: TRUE.}
}
\value{
A list with the function of parameters ,algorithms, elapse time, grn which a matrix which is the weighted adjacency matrix of the inferred network by the regression algorithm.
}
\description{
This is the main function to call different algorithms of regression for gene regulator network inference.
}
\details{
The demo function aims to call algorithms to solve optimization problem.
This functions provides 12 algorithms for users.
This demo run parallelly and all cores can be utilized to speed up.
We import 'foba' and 'lars' from CRAN to run 'FoBa' and 'LARS' algorithms.

LARS (least angle regression) algorithm is a variant of forward greedy methods proposed by
Efron et al. (2004) for approaching an approximate solution of problem:
\deqn{\begin{array}{l}\min ||Ax-b|{|^2}\\s.t.||x|{|_1} \le s\end{array}}
LARS is a hybrid of forward greedy selection and stagewise regression.

Combining the ideas of forward and backward greedy algorithms, Zhang (2001) designed an
adaptive forward-backward greedy (FoBa) algorithm for solving problem:
\deqn{\begin{array}{l}\min ||Ax-b|{|^2}\\s.t.||x|{|_0} \le s\end{array}}
FoBa adopts OMP to select features and takes adaptive backward steps to remove any mistake
caused by earlier forward steps. The backward step shall be employed when the increase of
loss function is no more than half of the decrease of loss function in earlier forward steps.
This principle of backward steps guarantee removing any mistake caused by earlier forward steps
and avoiding to earse the gain made in the forward steps. FoBa can fix the fundamental flaws of
both forward and backward greedy methods, and shares their fast implementation advantage.
}
\examples{
A <- matrix(rnorm(200,0,1),20,10)
B <- matrix(rnorm(1000,0,1),100)
X <- matrix(0,100,20)
s <- c(1:10)
TF <- paste0('G',1:20)
gene <- paste0('G',1:100)
res <- demo_reg(A, B, s, X, 'ADMM',max.steps = 200,TF, gene,
                p = FALSE,tau=10, cl.cores = 2,file=NULL,verbose=TRUE)
}
\references{
Efron, B., Hastie, T., Johnstone, I., and Tibshirani, R. (2004). "Least angle
regression", Annals of Statistics ,32, 407-499.

Zhang, T. (2011). "Adaptive forward-backward greedy algorithm for
learning sparse representations", IEEE Transactions on Information Theory, 57(7), 4689-4708.
}
\author{
Yaohua Hu <mayhhu@szu.edu.cn>

Xinlin Hu <ttxinlinhu@qq.com>

Yongqiang Zhou <zhouyq67@mail2.sysu.edu.cn>
}
